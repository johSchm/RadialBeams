{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287138e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.8.0\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TF Version: ' + str(tf.__version__))\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print('GPUs: ' + str(physical_devices))\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ead39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from src.model import VGG11\n",
    "from src.utils import angle_between\n",
    "from src.model import BIC\n",
    "from src.parsing import load_dataset\n",
    "from src.parsing import preprocess\n",
    "from src.parsing import instantiate_radial_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c4158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'coil100'\n",
    "target_size = 128 // 2\n",
    "model_path = './model/coil100.h5py'\n",
    "margin_padding = math.ceil(target_size * (math.sqrt(2) - 1))\n",
    "batch_size = 128\n",
    "n_beams = 16\n",
    "continuous = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beaff59",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "Reminder: First, load, pre-process and store a dataset via the [RadialBeam](./radialbeamsampling.ipynb) routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4f652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 17:35:14.475394: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-20 17:35:15.138228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 35742 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:43:00.0, compute capability: 8.6\n",
      "2022-05-20 17:35:27.939613: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-05-20 17:35:32.154793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "en_load_dataset = False\n",
    "\n",
    "if en_load_dataset:\n",
    "    train_dataset = tf.data.experimental.load('./data/{0}_train'.format(dataset_name)).batch(batch_size)\n",
    "    val_dataset = tf.data.experimental.load('./data/{0}_val'.format(dataset_name)).batch(batch_size)\n",
    "    test_dataset = tf.data.experimental.load('./data/{0}_test'.format(dataset_name)).batch(batch_size)\n",
    "else:\n",
    "    splits = [0.8, 0.1, 0.1]\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    n_train = int(splits[0] * float(dataset.cardinality()))\n",
    "    n_val = int(splits[1] * float(dataset.cardinality()))\n",
    "    n_test = int(splits[2] * float(dataset.cardinality()))\n",
    "\n",
    "    train_dataset = dataset.take(n_train)\n",
    "    val_dataset = dataset.skip(n_train).take(n_val)\n",
    "    test_dataset = dataset.skip(n_train).skip(n_val).take(n_train)\n",
    "\n",
    "    img_size = int(train_dataset.element_spec['image'].shape[0])\n",
    "    lines, angles = instantiate_radial_vectors(img_size + margin_padding, img_size + margin_padding,\n",
    "                                               beam_set_size=n_beams,\n",
    "                                               max_len=target_size)\n",
    "    train_dataset = preprocess(train_dataset, lines, angles, target_size=img_size + margin_padding,\n",
    "                               batch_size=batch_size, path='./training_dataset', continuous=continuous)\n",
    "    val_dataset = preprocess(val_dataset, lines, angles, target_size=img_size + margin_padding,\n",
    "                             batch_size=batch_size, path='./val_dataset', continuous=continuous)\n",
    "    test_dataset = preprocess(test_dataset, lines, angles, target_size=img_size + margin_padding,\n",
    "                              batch_size=batch_size, path='./test_dataset', continuous=continuous)\n",
    "\n",
    "_, n_beams, _, n_pixels, n_channels = train_dataset.element_spec['beam'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9b344",
   "metadata": {},
   "source": [
    "### Load the BIC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b26541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " beams (InputLayer)          [(None, 2, 16, 3, 64, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " bic (BIC)                   ((None, 16),              560226    \n",
      "                              (None, 2),                         \n",
      "                              (None, 2, 16, 128),                \n",
      "                              (None, 2, 128),                    \n",
      "                              (None, 16, 16),                    \n",
      "                              (None, 16, 128),                   \n",
      "                              (None, 16, 128),                   \n",
      "                              (None, 16, 16),                    \n",
      "                              (None, 128))                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 560,226\n",
      "Trainable params: 560,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input tensor (batch x (zero, theta) x beams x (2epsilon + 1) x D x C)\n",
    "in_beams = tf.keras.layers.Input([2, n_beams, 3, n_pixels, n_channels])\n",
    "\n",
    "bic = BIC(hidden=128, activation=tf.nn.leaky_relu, context=True,\n",
    "          l2_regularization=0.0, edge_factor=0.5, gcn_layers=3, dropout=0.0,\n",
    "          size_vector_field=n_beams, pixel_count_per_vector=n_pixels)\n",
    "\n",
    "# multiple output for introspection; for training and inference: prior and unit_vec are essential\n",
    "prior, unit_vec, beamencoding, ctx, similarity, \\\n",
    "beamencoding_zero, beamencoding_theta, angle_energy, rnn_encoding = bic(inputs=in_beams)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=in_beams, name='bic',\n",
    "                              outputs=(prior, unit_vec, beamencoding, ctx, similarity, \\\n",
    "                                       beamencoding_zero, beamencoding_theta, angle_energy, rnn_encoding))\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e19b8",
   "metadata": {},
   "source": [
    "### Crop and canonicalize methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeeccce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding(image):\n",
    "    cropped_image = tf.image.crop_to_bounding_box(image, margin_padding // 2, margin_padding // 2,\n",
    "                                                  target_size * 2, target_size * 2)\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def downstream_predict(downstream, sample, k=1, show=False):\n",
    "    # predict non-rotated image with downstream model\n",
    "    if k == 1:\n",
    "        non_rot_pred = downstream(remove_padding(sample['image']))\n",
    "    else:\n",
    "        non_rot_pred = tf.nn.top_k(downstream(remove_padding(sample['image'])), k=k)\n",
    "\n",
    "    # predict rotated and chopped off image\n",
    "    if k == 1:\n",
    "        crop_rot_pred = downstream(remove_padding(sample['rotated']))\n",
    "    else:\n",
    "        crop_rot_pred = tf.nn.top_k(downstream(remove_padding(sample['rotated'])), k=k)\n",
    "\n",
    "    # call BIC\n",
    "    pred_facts, pred_angle, conv_latents, gnn_latents, distance_matrix, \\\n",
    "    x1_emb, x2_emb, angle_energy, rnn_encoding = model(\n",
    "        tf.tile(sample['beam_rot'][:, None, ...], [1, 2, 1, 1, 1, 1]))\n",
    "\n",
    "    # project form complex vector to angle\n",
    "    pred_angle = np.array([angle_between(pred_angle[b], tf.cast([1., 0.], tf.float32), gpu=True)\n",
    "                           for b in range(tf.shape(pred_angle)[0])])\n",
    "\n",
    "    # smoothly rotate the image back\n",
    "    back_rot = tfa.image.rotate(sample['rotated'], 2 * math.pi - pred_angle,\n",
    "                                interpolation='bilinear')\n",
    "\n",
    "    # predict with downstream model\n",
    "    if k == 1:\n",
    "        if show:\n",
    "            plt.imshow(remove_padding(back_rot[0]))\n",
    "            plt.show()\n",
    "        canonic_pred = downstream(remove_padding(back_rot))\n",
    "    else:\n",
    "        canonic_pred = tf.nn.top_k(downstream(remove_padding(back_rot)), k=k)\n",
    "\n",
    "    return non_rot_pred, crop_rot_pred, canonic_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78d760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, axis=-1)\n",
    "train_df = pd.DataFrame(columns=['iteration', 'non_rot_loss', 'crop_rot_loss', 'canonic_loss'])\n",
    "valid_df = pd.DataFrame(columns=['iteration', 'non_rot_loss', 'crop_rot_loss', 'canonic_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]2022-05-20 17:36:31.591068: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 0 of node statefulpartitionedcall_117_RetVal was passed float from StatefulPartitionedCall/lstm0/PartitionedCall:7 incompatible with expected variant.\n",
      "2022-05-20 17:36:31.620525: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] layout failed: OUT_OF_RANGE: src_output = 30, but num_outputs is only 30\n",
      "2022-05-20 17:36:31.672020: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: INVALID_ARGUMENT: Input 0 of node statefulpartitionedcall_117_RetVal was passed float from StatefulPartitionedCall/lstm0/PartitionedCall:7 incompatible with expected variant.\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2022-05-20 17:36:31.684079: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 0 of node statefulpartitionedcall_117_RetVal was passed float from StatefulPartitionedCall/lstm0/PartitionedCall:7 incompatible with expected variant.\n",
      "2022-05-20 17:36:31.736340: W tensorflow/core/common_runtime/process_function_library_runtime.cc:932] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Input 0 of node statefulpartitionedcall_117_RetVal was passed float from StatefulPartitionedCall/lstm0/PartitionedCall:7 incompatible with expected variant.\n",
      "100%|██████████| 8/8 [03:14<00:00, 24.35s/it]\n",
      "100%|██████████| 8/8 [03:08<00:00, 23.59s/it]\n",
      " 38%|███▊      | 3/8 [01:11<02:00, 24.07s/it]"
     ]
    }
   ],
   "source": [
    "n_runs = 5\n",
    "epochs = 8\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    downstream = VGG11((target_size * 2, target_size * 2, 3), 100)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    for e in tqdm(range(epochs)):\n",
    "\n",
    "        # validation, before training to log also the init behaviour of the model\n",
    "        for i, sample in enumerate(val_dataset):\n",
    "            non_rot_pred, crop_rot_pred, canonic_pred = downstream_predict(downstream, sample)\n",
    "            valid_df = valid_df.append(pd.DataFrame({\n",
    "                'iteration': [e * int(val_dataset.cardinality().numpy()) + i],\n",
    "                'non_rot_loss': [float(cce(tf.one_hot(sample['label'], 100), non_rot_pred).numpy())],\n",
    "                'crop_rot_loss': [float(cce(tf.one_hot(sample['label'], 100), crop_rot_pred).numpy())],\n",
    "                'canonic_loss': [float(cce(tf.one_hot(sample['label'], 100), canonic_pred).numpy())]\n",
    "            }), ignore_index=True)\n",
    "            pass\n",
    "\n",
    "        # training\n",
    "        for i, sample in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                non_rot_pred, crop_rot_pred, canonic_pred = downstream_predict(downstream, sample,\n",
    "                                                                               show=False)#True if i == 0 else False)\n",
    "                loss = cce(tf.one_hot(sample['label'], 100), non_rot_pred)\n",
    "                train_df = train_df.append(pd.DataFrame({\n",
    "                    'iteration': [e * int(train_dataset.cardinality().numpy()) + i],\n",
    "                    'non_rot_loss': [float(cce(tf.one_hot(sample['label'], 100), non_rot_pred).numpy())],\n",
    "                    'crop_rot_loss': [float(cce(tf.one_hot(sample['label'], 100), crop_rot_pred).numpy())],\n",
    "                    'canonic_loss': [float(cce(tf.one_hot(sample['label'], 100), canonic_pred).numpy())]\n",
    "                }), ignore_index=True)\n",
    "            grads_downstream = tape.gradient(loss, downstream.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads_downstream, downstream.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#629FCA', '#FDA556', '#6BBC6B', '#E26768', '#B292CE']\n",
    "\n",
    "ax = sns.lineplot(data=valid_df, x='iteration', y='non_rot_loss', label='non_rot_loss', ci='sd',\n",
    "             palette=colors[0], alpha=0.7)\n",
    "ax = sns.lineplot(data=valid_df, x='iteration', y='crop_rot_loss', label='crop_rot_loss', ci='sd',\n",
    "             palette=colors[1], alpha=0.7)\n",
    "ax = sns.lineplot(data=valid_df, x='iteration', y='canonic_loss', label='canonic_loss', ci='sd',\n",
    "             palette=colors[2], alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Cross Entropy')\n",
    "ax.legend().remove()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
